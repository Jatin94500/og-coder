{
    "cells": [{
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Space Weather Monitoring & Solar Storm Risk Prediction System\n",
                "## Complete Implementation for Google Colab\n",
                "\n",
                "This notebook implements a comprehensive system for:\n",
                "- Real-time space weather data collection\n",
                "- Solar flare prediction\n",
                "- Geomagnetic storm forecasting\n",
                "- Satellite and communication system risk assessment\n",
                "- Interactive visualization dashboard"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Install Required Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install requests pandas numpy matplotlib seaborn scikit-learn tensorflow plotly\n",
                "!pip install xgboost lightgbm astropy sunpy beautifulsoup4 lxml\n",
                "!pip install ipywidgets folium"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import requests\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import plotly.graph_objects as go\n",
                "import plotly.express as px\n",
                "from plotly.subplots import make_subplots\n",
                "from datetime import datetime, timedelta\n",
                "import json\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Machine Learning\n",
                "from sklearn.model_selection import train_test_split, cross_val_score\n",
                "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
                "from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor\n",
                "from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error, r2_score\n",
                "import xgboost as xgb\n",
                "import lightgbm as lgb\n",
                "\n",
                "# Deep Learning\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "from tensorflow.keras.models import Sequential, Model\n",
                "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Bidirectional, Attention\n",
                "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
                "\n",
                "# Set style\n",
                "plt.style.use('seaborn-v0_8-darkgrid')\n",
                "sns.set_palette('husl')\n",
                "\n",
                "print(\"✓ All libraries imported successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Data Collection Module"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SpaceWeatherDataCollector:\n",
                "    \"\"\"\n",
                "    Collects real-time and historical space weather data from multiple sources\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self):\n",
                "        self.noaa_base_url = \"https://services.swpc.noaa.gov/json\"\n",
                "        self.nasa_donki_url = \"https://api.nasa.gov/DONKI\"\n",
                "        self.nasa_api_key = \"DEMO_KEY\"  # Replace with your NASA API key\n",
                "        \n",
                "    def get_solar_wind_data(self):\n",
                "        \"\"\"Fetch real-time solar wind data\"\"\"\n",
                "        try:\n",
                "            url = f\"{self.noaa_base_url}/plasma-7-day.json\"\n",
                "            response = requests.get(url, timeout=10)\n",
                "            data = response.json()\n",
                "            df = pd.DataFrame(data)\n",
                "            df['time_tag'] = pd.to_datetime(df['time_tag'])\n",
                "            return df\n",
                "        except Exception as e:\n",
                "            print(f\"Error fetching solar wind data: {e}\")\n",
                "            return None\n",
                "    \n",
                "    def get_geomagnetic_data(self):\n",
                "        \"\"\"Fetch geomagnetic K-index data\"\"\"\n",
                "        try:\n",
                "            url = f\"{self.noaa_base_url}/planetary_k_index_1m.json\"\n",
                "            response = requests.get(url, timeout=10)\n",
                "            data = response.json()\n",
                "            df = pd.DataFrame(data)\n",
                "            df['time_tag'] = pd.to_datetime(df['time_tag'])\n",
                "            return df\n",
                "        except Exception as e:\n",
                "            print(f\"Error fetching geomagnetic data: {e}\")\n",
                "            return None\n",
                "    \n",
                "    def get_solar_flares(self, start_date, end_date):\n",
                "        \"\"\"Fetch solar flare events from NASA DONKI\"\"\"\n",
                "        try:\n",
                "            url = f\"{self.nasa_donki_url}/FLR\"\n",
                "            params = {\n",
                "                'startDate': start_date.strftime('%Y-%m-%d'),\n",
                "                'endDate': end_date.strftime('%Y-%m-%d'),\n",
                "                'api_key': self.nasa_api_key\n",
                "            }\n",
                "            response = requests.get(url, params=params, timeout=10)\n",
                "            data = response.json()\n",
                "            return pd.DataFrame(data) if data else None\n",
                "        except Exception as e:\n",
                "            print(f\"Error fetching solar flares: {e}\")\n",
                "            return None\n",
                "    \n",
                "    def get_cme_data(self, start_date, end_date):\n",
                "        \"\"\"Fetch Coronal Mass Ejection data\"\"\"\n",
                "        try:\n",
                "            url = f\"{self.nasa_donki_url}/CME\"\n",
                "            params = {\n",
                "                'startDate': start_date.strftime('%Y-%m-%d'),\n",
                "                'endDate': end_date.strftime('%Y-%m-%d'),\n",
                "                'api_key': self.nasa_api_key\n",
                "            }\n",
                "            response = requests.get(url, params=params, timeout=10)\n",
                "            data = response.json()\n",
                "            return pd.DataFrame(data) if data else None\n",
                "        except Exception as e:\n",
                "            print(f\"Error fetching CME data: {e}\")\n",
                "            return None\n",
                "    \n",
                "    def get_xray_flux(self):\n",
                "        \"\"\"Fetch X-ray flux data (GOES satellite)\"\"\"\n",
                "        try:\n",
                "            url = f\"{self.noaa_base_url}/goes/primary/xrays-7-day.json\"\n",
                "            response = requests.get(url, timeout=10)\n",
                "            data = response.json()\n",
                "            df = pd.DataFrame(data)\n",
                "            df['time_tag'] = pd.to_datetime(df['time_tag'])\n",
                "            return df\n",
                "        except Exception as e:\n",
                "            print(f\"Error fetching X-ray flux: {e}\")\n",
                "            return None\n",
                "    \n",
                "    def get_proton_flux(self):\n",
                "        \"\"\"Fetch proton flux data\"\"\"\n",
                "        try:\n",
                "            url = f\"{self.noaa_base_url}/goes/primary/integral-protons-plot-6-hour.json\"\n",
                "            response = requests.get(url, timeout=10)\n",
                "            data = response.json()\n",
                "            df = pd.DataFrame(data)\n",
                "            df['time_tag'] = pd.to_datetime(df['time_tag'])\n",
                "            return df\n",
                "        except Exception as e:\n",
                "            print(f\"Error fetching proton flux: {e}\")\n",
                "            return None\n",
                "\n",
                "# Initialize collector\n",
                "collector = SpaceWeatherDataCollector()\n",
                "print(\"✓ Data collector initialized\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Fetch Real-Time Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Fetching real-time space weather data...\\n\")\n",
                "\n",
                "# Fetch current data\n",
                "solar_wind_df = collector.get_solar_wind_data()\n",
                "geomag_df = collector.get_geomagnetic_data()\n",
                "xray_df = collector.get_xray_flux()\n",
                "proton_df = collector.get_proton_flux()\n",
                "\n",
                "# Fetch historical events (last 30 days)\n",
                "end_date = datetime.now()\n",
                "start_date = end_date - timedelta(days=30)\n",
                "flares_df = collector.get_solar_flares(start_date, end_date)\n",
                "cme_df = collector.get_cme_data(start_date, end_date)\n",
                "\n",
                "# Display data summaries\n",
                "if solar_wind_df is not None:\n",
                "    print(f\"✓ Solar Wind Data: {len(solar_wind_df)} records\")\n",
                "    print(f\"  Latest: {solar_wind_df['time_tag'].max()}\")\n",
                "    \n",
                "if geomag_df is not None:\n",
                "    print(f\"✓ Geomagnetic Data: {len(geomag_df)} records\")\n",
                "    print(f\"  Current Kp Index: {geomag_df['kp_index'].iloc[-1] if len(geomag_df) > 0 else 'N/A'}\")\n",
                "    \n",
                "if xray_df is not None:\n",
                "    print(f\"✓ X-ray Flux Data: {len(xray_df)} records\")\n",
                "    \n",
                "if flares_df is not None:\n",
                "    print(f\"✓ Solar Flares (30 days): {len(flares_df)} events\")\n",
                "    \n",
                "if cme_df is not None:\n",
                "    print(f\"✓ CME Events (30 days): {len(cme_df)} events\")\n",
                "\n",
                "print(\"\\n✓ Data collection complete\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Feature Engineering Module"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class FeatureEngineering:\n",
                "    \"\"\"\n",
                "    Creates features for machine learning models\n",
                "    \"\"\"\n",
                "    \n",
                "    @staticmethod\n",
                "    def create_time_features(df, time_column='time_tag'):\n",
                "        \"\"\"Extract temporal features\"\"\"\n",
                "        df = df.copy()\n",
                "        df['hour'] = df[time_column].dt.hour\n",
                "        df['day'] = df[time_column].dt.day\n",
                "        df['month'] = df[time_column].dt.month\n",
                "        df['day_of_week'] = df[time_column].dt.dayofweek\n",
                "        df['day_of_year'] = df[time_column].dt.dayofyear\n",
                "        return df\n",
                "    \n",
                "    @staticmethod\n",
                "    def create_rolling_features(df, columns, windows=[3, 6, 12, 24]):\n",
                "        \"\"\"Create rolling statistics\"\"\"\n",
                "        df = df.copy()\n",
                "        for col in columns:\n",
                "            if col in df.columns:\n",
                "                for window in windows:\n",
                "                    df[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window, min_periods=1).mean()\n",
                "                    df[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window, min_periods=1).std()\n",
                "                    df[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window, min_periods=1).max()\n",
                "                    df[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window, min_periods=1).min()\n",
                "        return df\n",
                "    \n",
                "    @staticmethod\n",
                "    def create_lag_features(df, columns, lags=[1, 3, 6, 12]):\n",
                "        \"\"\"Create lagged features\"\"\"\n",
                "        df = df.copy()\n",
                "        for col in columns:\n",
                "            if col in df.columns:\n",
                "                for lag in lags:\n",
                "                    df[f'{col}_lag_{lag}'] = df[col].shift(lag)\n",
                "        return df\n",
                "    \n",
                "    @staticmethod\n",
                "    def create_rate_of_change(df, columns):\n",
                "        \"\"\"Calculate rate of change\"\"\"\n",
                "        df = df.copy()\n",
                "        for col in columns:\n",
                "            if col in df.columns:\n",
                "                df[f'{col}_roc'] = df[col].pct_change()\n",
                "                df[f'{col}_diff'] = df[col].diff()\n",
                "        return df\n",
                "    \n",
                "    @staticmethod\n",
                "    def classify_flare_intensity(flux_value):\n",
                "        \"\"\"Classify X-ray flux into flare classes\"\"\"\n",
                "        if flux_value < 1e-8:\n",
                "            return 'A'\n",
                "        elif flux_value < 1e-7:\n",
                "            return 'B'\n",
                "        elif flux_value < 1e-6:\n",
                "            return 'C'\n",
                "        elif flux_value < 1e-5:\n",
                "            return 'M'\n",
                "        else:\n",
                "            return 'X'\n",
                "    \n",
                "    @staticmethod\n",
                "    def classify_geomag_storm(kp_value):\n",
                "        \"\"\"Classify geomagnetic storm intensity\"\"\"\n",
                "        if kp_value < 5:\n",
                "            return 'None'\n",
                "        elif kp_value < 6:\n",
                "            return 'G1-Minor'\n",
                "        elif kp_value < 7:\n",
                "            return 'G2-Moderate'\n",
                "        elif kp_value < 8:\n",
                "            return 'G3-Strong'\n",
                "        elif kp_value < 9:\n",
                "            return 'G4-Severe'\n",
                "        else:\n",
                "            return 'G5-Extreme'\n",
                "\n",
                "print(\"✓ Feature engineering module loaded\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Generate Synthetic Training Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_synthetic_training_data(n_samples=10000):\n",
                "    \"\"\"\n",
                "    Generate synthetic space weather data for model training\n",
                "    Based on realistic parameter ranges\n",
                "    \"\"\"\n",
                "    np.random.seed(42)\n",
                "    \n",
                "    # Generate timestamps\n",
                "    start_date = datetime(2020, 1, 1)\n",
                "    timestamps = [start_date + timedelta(hours=i) for i in range(n_samples)]\n",
                "    \n",
                "    # Solar wind parameters (realistic ranges)\n",
                "    solar_wind_speed = np.random.normal(450, 100, n_samples)  # km/s\n",
                "    solar_wind_speed = np.clip(solar_wind_speed, 250, 900)\n",
                "    \n",
                "    proton_density = np.random.lognormal(1.5, 0.5, n_samples)  # particles/cm³\n",
                "    proton_density = np.clip(proton_density, 0.5, 50)\n",
                "    \n",
                "    # IMF (Interplanetary Magnetic Field)\n",
                "    bt = np.random.gamma(2, 2, n_samples)  # nT\n",
                "    bz = np.random.normal(0, 3, n_samples)  # nT\n",
                "    \n",
                "    # Temperature\n",
                "    temperature = np.random.lognormal(11, 0.5, n_samples)  # Kelvin\n",
                "    \n",
                "    # X-ray flux (log scale)\n",
                "    xray_flux = np.random.lognormal(-17, 2, n_samples)\n",
                "    xray_flux = np.clip(xray_flux, 1e-9, 1e-3)\n",
                "    \n",
                "    # Calculate Kp index (simplified model)\n",
                "    # Higher solar wind speed + southward Bz = higher Kp\n",
                "    kp_base = (solar_wind_speed - 300) / 100 + np.abs(np.minimum(bz, 0)) / 2\n",
                "    kp_noise = np.random.normal(0, 0.5, n_samples)\n",
                "    kp_index = np.clip(kp_base + kp_noise, 0, 9)\n",
                "    \n",
                "    # Flare probability (based on X-ray flux)\n",
                "    flare_prob = 1 / (1 + np.exp(-10 * (np.log10(xray_flux) + 6)))\n",
                "    flare_occurred = (np.random.random(n_samples) < flare_prob).astype(int)\n",
                "    \n",
                "    # Flare class\n",
                "    flare_class = [FeatureEngineering.classify_flare_intensity(x) for x in xray_flux]\n",
                "    \n",
                "    # Geomagnetic storm classification\n",
                "    storm_class = [FeatureEngineering.classify_geomag_storm(k) for k in kp_index]\n",
                "    \n",
                "    # Create DataFrame\n",
                "    df = pd.DataFrame({\n",
                "        'timestamp': timestamps,\n",
                "        'solar_wind_speed': solar_wind_speed,\n",
                "        'proton_density': proton_density,\n",
                "        'bt': bt,\n",
                "        'bz': bz,\n",
                "        'temperature': temperature,\n",
                "        'xray_flux': xray_flux,\n",
                "        'kp_index': kp_index,\n",
                "        'flare_occurred': flare_occurred,\n",
                "        'flare_class': flare_class,\n",
                "        'storm_class': storm_class\n",
                "    })\n",
                "    \n",
                "    return df\n",
                "\n",
                "# Generate training data\n",
                "print(\"Generating synthetic training data...\")\n",
                "training_data = generate_synthetic_training_data(10000)\n",
                "print(f\"✓ Generated {len(training_data)} training samples\")\n",
                "print(f\"\\nData shape: {training_data.shape}\")\n",
                "print(f\"\\nFlare distribution:\")\n",
                "print(training_data['flare_class'].value_counts())\n",
                "print(f\"\\nStorm distribution:\")\n",
                "print(training_data['storm_class'].value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Prepare Features for ML Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply feature engineering\n",
                "fe = FeatureEngineering()\n",
                "\n",
                "print(\"Creating features...\")\n",
                "training_data = fe.create_time_features(training_data, 'timestamp')\n",
                "\n",
                "numeric_cols = ['solar_wind_speed', 'proton_density', 'bt', 'bz', 'temperature', 'xray_flux']\n",
                "training_data = fe.create_rolling_features(training_data, numeric_cols, windows=[6, 12, 24])\n",
                "training_data = fe.create_lag_features(training_data, numeric_cols, lags=[1, 3, 6])\n",
                "training_data = fe.create_rate_of_change(training_data, numeric_cols)\n",
                "\n",
                "# Fill NaN values\n",
                "training_data = training_data.fillna(method='bfill').fillna(method='ffill')\n",
                "\n",
                "print(f\"✓ Feature engineering complete\")\n",
                "print(f\"Total features: {training_data.shape[1]}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}